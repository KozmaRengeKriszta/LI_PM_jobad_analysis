{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766fe92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import time\n",
    "import openai\n",
    "openai.api_key = \"TYPE HERE YOUR API KEY\"\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6db480",
   "metadata": {},
   "source": [
    "## Determination of language skills using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and make new columns\n",
    "df = pd.read_csv('LI_PM_jobDesc.csv', delimiter = ',')\n",
    "df['languageSkills'] = ['' for i in range(len(df))]\n",
    "\n",
    "# definition of keywords\n",
    "relevant_words = ['english', 'hungarian', 'german', 'french', 'spanish', 'romanian', 'italian',\n",
    "                  'angol', 'magyar', 'német', 'francia', 'spanyol', 'román', 'olasz']\n",
    "\n",
    "# tokenization the jobDescriptions\n",
    "for index, row in df.iterrows():\n",
    "    tokens = nltk.word_tokenize(row['jobDescription'].lower())\n",
    "\n",
    "    # definition of language skills\n",
    "    for token in tokens:\n",
    "        if token in relevant_words:\n",
    "            if df.at[index, 'languageSkills']:\n",
    "                df.at[index, 'languageSkills'] += ', '\n",
    "            df.at[index, 'languageSkills'] += token\n",
    "\n",
    "# print results\n",
    "df[['companyName', 'languageSkills']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225bf64f",
   "metadata": {},
   "source": [
    "## Determination of language skills using AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b19763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Létrehozzuk az új dataframe-et\n",
    "LI_PM_jobad = pd.read_csv('LI_PM_jobDesc.csv', delimiter = ',')\n",
    "df2 = pd.DataFrame()\n",
    "df2['companyName'] = LI_PM_jobad['companyName']\n",
    "df2['jobDescription'] = LI_PM_jobad['jobDescription']\n",
    "df2['languageSkills'] = ''\n",
    "\n",
    "#iterate through the dataframe\n",
    "for index, row in df2.iterrows():\n",
    "    \n",
    "    prompt_languageSkills = row['jobDescription'] + \"/n --- /n This is a product manager job description.\\\n",
    "                            Define expectations related to language skills of applicant.\\\n",
    "                            Don't write complete sentences, just list the languages, the level of language knowledge,\\\n",
    "                            and whether the use of the language is expected in written or spoken.\\\n",
    "                            Template: {language}, {level}, written or spoken or both.\\\n",
    "                            Choose the level from this list: Beginner, Intermediate, Advanced, Proficient, Native!\\\n",
    "                            Answer the question as truthfully as possible using the provided text.\\\n",
    "                            If the expected language skills cannot be clearly determined based on\\\n",
    "                            the description, use just this value: 'Unknown' and don't write anything else.\"\n",
    "        \n",
    "    response_languageSkills = openai.ChatCompletion.create(\n",
    "        model = \"gpt-4\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful data science assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_languageSkills}],\n",
    "        max_tokens=50,\n",
    "        temperature=0)\n",
    "    \n",
    "    message_languageSkills = response_languageSkills['choices'][0]['message']['content'].strip()\n",
    "\n",
    "    df2.loc[index, 'languageSkills'] = message_languageSkills\n",
    "    \n",
    "    time.sleep(2)\n",
    "        \n",
    "    #if index % 10 == 0:\n",
    "    print(f\"Processed row {index} : {message_languageSkills}\")\n",
    "        \n",
    "#print results\n",
    "df2[['companyName', 'languageSkills']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366bd0c7",
   "metadata": {},
   "source": [
    "## Further analysis with chatGPT\n",
    "\n",
    "At first, I classified the text fragments collected by the AI from the 212 job advertisements into 2 large groups. Then, I copied these groups one by one to ChatGPT and asked it to help me with the analysis using the following prompt:\n",
    "\n",
    "\"I will show some job advertisement details about language skills given by employers - from now on, I will refer to this group of advertisements as jobAd_n.\n",
    "Tasks:\n",
    "1) Combine similar language skills in the jobAd_n advertisement group!\n",
    "2) Then, collect the 15 most frequently occurring language skills from this jobAd_n group!\n",
    "3) Finally, make a table of how many advertisements appeared in the jobAd_n group!\"\n",
    "\n",
    "Then, I saved the table created by ChatGPT for myself and performed the same analysis with all advertisement groups. Finally, I copied the tables created after all 2 groups and asked ChatGPT to combine similar language skills and make a last combined table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c04bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
